{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/yanncauchepin/ExternalDisk/Datasets/ComputerVisionImages/digit_recognizer/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/media/yanncauchepin/ExternalDisk/Datasets/ComputerVisionImages/digit_recognizer/train.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/media/yanncauchepin/ExternalDisk/Datasets/ComputerVisionImages/digit_recognizer/test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Git/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Git/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Git/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Git/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Git/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/yanncauchepin/ExternalDisk/Datasets/ComputerVisionImages/digit_recognizer/train.csv'"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('/media/yanncauchepin/ExternalDisk/Datasets/ComputerVisionImages/digit_recognizer/train.csv')\n",
    "df_test = pd.read_csv('/media/yanncauchepin/ExternalDisk/Datasets/ComputerVisionImages/digit_recognizer/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       count\n",
      "label       \n",
      "1       4684\n",
      "7       4401\n",
      "3       4351\n",
      "9       4188\n",
      "2       4177\n",
      "6       4137\n",
      "0       4132\n",
      "4       4072\n",
      "8       4063\n",
      "5       3795\n"
     ]
    }
   ],
   "source": [
    "distinct_labels = df_train['label'].value_counts()\n",
    "print(pd.DataFrame(distinct_labels))\n",
    "classes = len(df_train[\"label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def evaluate_classifier(y_true, y_pred):\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Metric': ['F1 Score', 'Precision', 'Recall'],\n",
    "        'Value': [f1, precision, recall]\n",
    "    })\n",
    "    \n",
    "    cm_df = pd.DataFrame(cm, columns=df_train[\"label\"].unique(), index=df_train[\"label\"].unique())\n",
    "    \n",
    "    return metrics_df, cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(df_train['label'])\n",
    "X_train = np.array(df_train.drop('label', axis=1))\n",
    "X_test = np.array(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = X_train / 255.0\n",
    "X_valid_norm = X_valid / 255.0\n",
    "X_test_norm = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(      Metric     Value\n",
      "0   F1 Score  0.962301\n",
      "1  Precision  0.963080\n",
      "2     Recall  0.962381,      1    0    4    7    3    5    8    9    2    6\n",
      "1  817    0    1    0    0    4    4    0    0    1\n",
      "0    0  934    1    0    0    0    0    2    0    0\n",
      "4    9   17  789    3    1    2    0   13    0    1\n",
      "7    2    6    5  831    0   14    0    5    3    4\n",
      "3    0   10    0    0  783    0    1    1    0   19\n",
      "5    4    5    0   10    0  720    7    0    3   10\n",
      "8    5    2    0    0    1    4  815    0    0    0\n",
      "9    0   10    0    0    1    0    0  862    0    7\n",
      "2    9   15    2   15    3   18    3    3  732   13\n",
      "6    4    1    1    3   10    3    0   15    0  801)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=classes)\n",
    "knn_classifier.fit(X_train_norm, y_train)\n",
    "\n",
    "y_pred = knn_classifier.predict(X_valid_norm)\n",
    "\n",
    "knn_classifier_assessement = evaluate_classifier(y_valid, y_pred)\n",
    "print(knn_classifier_assessement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(      Metric     Value\n",
      "0   F1 Score  0.975350\n",
      "1  Precision  0.975385\n",
      "2     Recall  0.975357,      1    0    4    7    3    5    8    9    2    6\n",
      "1  812    0    1    0    2    1    6    0    2    3\n",
      "0    0  930    2    3    0    0    0    0    2    0\n",
      "4    0    0  815    4    5    0    0    8    2    1\n",
      "7    3    2    7  832    3   10    0    3    3    7\n",
      "3    1    4    0    0  794    0    2    1    1   11\n",
      "5    4    1    1    7    1  732    6    0    4    3\n",
      "8    0    1    1    0    0    5  817    0    3    0\n",
      "9    0    3    4    2    2    1    0  861    1    6\n",
      "2    3    1    0    2    0    6    3    1  788    9\n",
      "6    3    2    0    3    4    2    0    9    3  812)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_classifier = XGBClassifier(n_estimators=1000, max_depth=4, learning_rate=0.1,  eval_metric='logloss')\n",
    "xgb_classifier.fit(X_train_norm, y_train, verbose=1)\n",
    "\n",
    "y_pred = xgb_classifier.predict(X_valid_norm)\n",
    "\n",
    "xgb_classifier_assessement = evaluate_classifier(y_valid, y_pred)\n",
    "print(xgb_classifier_assessement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.0962791\ttotal: 397ms\tremaining: 6m 36s\n",
      "2:\tlearn: 1.8310850\ttotal: 907ms\tremaining: 5m 1s\n",
      "4:\tlearn: 1.6302713\ttotal: 1.45s\tremaining: 4m 48s\n",
      "6:\tlearn: 1.4751555\ttotal: 1.96s\tremaining: 4m 37s\n",
      "8:\tlearn: 1.3460221\ttotal: 2.44s\tremaining: 4m 28s\n",
      "10:\tlearn: 1.2434894\ttotal: 2.94s\tremaining: 4m 24s\n",
      "12:\tlearn: 1.1528075\ttotal: 3.46s\tremaining: 4m 22s\n",
      "14:\tlearn: 1.0777297\ttotal: 3.91s\tremaining: 4m 17s\n",
      "16:\tlearn: 1.0118651\ttotal: 4.4s\tremaining: 4m 14s\n",
      "18:\tlearn: 0.9546359\ttotal: 4.84s\tremaining: 4m 9s\n",
      "20:\tlearn: 0.8999357\ttotal: 5.3s\tremaining: 4m 7s\n",
      "22:\tlearn: 0.8518069\ttotal: 5.8s\tremaining: 4m 6s\n",
      "24:\tlearn: 0.8097365\ttotal: 6.33s\tremaining: 4m 6s\n",
      "26:\tlearn: 0.7709663\ttotal: 6.89s\tremaining: 4m 8s\n",
      "28:\tlearn: 0.7421569\ttotal: 7.36s\tremaining: 4m 6s\n",
      "30:\tlearn: 0.7083525\ttotal: 7.89s\tremaining: 4m 6s\n",
      "32:\tlearn: 0.6796631\ttotal: 8.36s\tremaining: 4m 5s\n",
      "34:\tlearn: 0.6590664\ttotal: 8.73s\tremaining: 4m\n",
      "36:\tlearn: 0.6324410\ttotal: 9.23s\tremaining: 4m\n",
      "38:\tlearn: 0.6080263\ttotal: 9.72s\tremaining: 3m 59s\n",
      "40:\tlearn: 0.5898589\ttotal: 10.1s\tremaining: 3m 56s\n",
      "42:\tlearn: 0.5726132\ttotal: 10.6s\tremaining: 3m 55s\n",
      "44:\tlearn: 0.5537372\ttotal: 11s\tremaining: 3m 54s\n",
      "46:\tlearn: 0.5393484\ttotal: 11.4s\tremaining: 3m 51s\n",
      "48:\tlearn: 0.5208162\ttotal: 11.9s\tremaining: 3m 51s\n",
      "50:\tlearn: 0.5125713\ttotal: 12.3s\tremaining: 3m 49s\n",
      "52:\tlearn: 0.4922973\ttotal: 12.8s\tremaining: 3m 49s\n",
      "54:\tlearn: 0.4795289\ttotal: 13.3s\tremaining: 3m 48s\n",
      "56:\tlearn: 0.4695192\ttotal: 13.7s\tremaining: 3m 46s\n",
      "58:\tlearn: 0.4590443\ttotal: 14.1s\tremaining: 3m 44s\n",
      "60:\tlearn: 0.4494728\ttotal: 14.5s\tremaining: 3m 43s\n",
      "62:\tlearn: 0.4401861\ttotal: 15s\tremaining: 3m 42s\n",
      "64:\tlearn: 0.4304036\ttotal: 15.4s\tremaining: 3m 41s\n",
      "66:\tlearn: 0.4225964\ttotal: 15.8s\tremaining: 3m 39s\n",
      "68:\tlearn: 0.4113094\ttotal: 16.3s\tremaining: 3m 39s\n",
      "70:\tlearn: 0.4017322\ttotal: 16.7s\tremaining: 3m 38s\n",
      "72:\tlearn: 0.3911568\ttotal: 17.2s\tremaining: 3m 37s\n",
      "74:\tlearn: 0.3849836\ttotal: 17.6s\tremaining: 3m 36s\n",
      "76:\tlearn: 0.3802431\ttotal: 18s\tremaining: 3m 35s\n",
      "78:\tlearn: 0.3745376\ttotal: 18.5s\tremaining: 3m 35s\n",
      "80:\tlearn: 0.3688938\ttotal: 19.1s\tremaining: 3m 36s\n",
      "82:\tlearn: 0.3635634\ttotal: 19.5s\tremaining: 3m 35s\n",
      "84:\tlearn: 0.3574191\ttotal: 20s\tremaining: 3m 35s\n",
      "86:\tlearn: 0.3504235\ttotal: 20.5s\tremaining: 3m 35s\n",
      "88:\tlearn: 0.3429533\ttotal: 21s\tremaining: 3m 34s\n",
      "90:\tlearn: 0.3378561\ttotal: 21.4s\tremaining: 3m 33s\n",
      "92:\tlearn: 0.3342969\ttotal: 21.8s\tremaining: 3m 32s\n",
      "94:\tlearn: 0.3296151\ttotal: 22.2s\tremaining: 3m 31s\n",
      "96:\tlearn: 0.3238101\ttotal: 22.7s\tremaining: 3m 31s\n",
      "98:\tlearn: 0.3198928\ttotal: 23.1s\tremaining: 3m 30s\n",
      "100:\tlearn: 0.3151003\ttotal: 23.6s\tremaining: 3m 29s\n",
      "102:\tlearn: 0.3110144\ttotal: 24s\tremaining: 3m 29s\n",
      "104:\tlearn: 0.3052432\ttotal: 24.5s\tremaining: 3m 28s\n",
      "106:\tlearn: 0.3008529\ttotal: 24.9s\tremaining: 3m 27s\n",
      "108:\tlearn: 0.2957537\ttotal: 25.3s\tremaining: 3m 27s\n",
      "110:\tlearn: 0.2924530\ttotal: 25.7s\tremaining: 3m 25s\n",
      "112:\tlearn: 0.2896345\ttotal: 26.1s\tremaining: 3m 24s\n",
      "114:\tlearn: 0.2859364\ttotal: 26.5s\tremaining: 3m 24s\n",
      "116:\tlearn: 0.2834063\ttotal: 26.9s\tremaining: 3m 23s\n",
      "118:\tlearn: 0.2791145\ttotal: 27.3s\tremaining: 3m 22s\n",
      "120:\tlearn: 0.2777563\ttotal: 27.7s\tremaining: 3m 21s\n",
      "122:\tlearn: 0.2750182\ttotal: 28.2s\tremaining: 3m 20s\n",
      "124:\tlearn: 0.2720502\ttotal: 28.6s\tremaining: 3m 20s\n",
      "126:\tlearn: 0.2698345\ttotal: 29s\tremaining: 3m 19s\n",
      "128:\tlearn: 0.2670331\ttotal: 29.4s\tremaining: 3m 18s\n",
      "130:\tlearn: 0.2643696\ttotal: 29.8s\tremaining: 3m 17s\n",
      "132:\tlearn: 0.2613547\ttotal: 30.2s\tremaining: 3m 16s\n",
      "134:\tlearn: 0.2594214\ttotal: 30.6s\tremaining: 3m 16s\n",
      "136:\tlearn: 0.2575569\ttotal: 31s\tremaining: 3m 15s\n",
      "138:\tlearn: 0.2562454\ttotal: 31.4s\tremaining: 3m 14s\n",
      "140:\tlearn: 0.2540742\ttotal: 31.7s\tremaining: 3m 13s\n",
      "142:\tlearn: 0.2516578\ttotal: 32.1s\tremaining: 3m 12s\n",
      "144:\tlearn: 0.2500208\ttotal: 32.5s\tremaining: 3m 11s\n",
      "146:\tlearn: 0.2492489\ttotal: 32.9s\tremaining: 3m 10s\n",
      "148:\tlearn: 0.2478507\ttotal: 33.3s\tremaining: 3m 10s\n",
      "150:\tlearn: 0.2463826\ttotal: 33.7s\tremaining: 3m 9s\n",
      "152:\tlearn: 0.2441171\ttotal: 34.1s\tremaining: 3m 8s\n",
      "154:\tlearn: 0.2425247\ttotal: 34.5s\tremaining: 3m 7s\n",
      "156:\tlearn: 0.2416206\ttotal: 34.9s\tremaining: 3m 7s\n",
      "158:\tlearn: 0.2406669\ttotal: 35.3s\tremaining: 3m 6s\n",
      "160:\tlearn: 0.2394423\ttotal: 35.6s\tremaining: 3m 5s\n",
      "162:\tlearn: 0.2376949\ttotal: 36s\tremaining: 3m 4s\n",
      "164:\tlearn: 0.2350693\ttotal: 36.4s\tremaining: 3m 4s\n",
      "166:\tlearn: 0.2341459\ttotal: 36.8s\tremaining: 3m 3s\n",
      "168:\tlearn: 0.2328910\ttotal: 37.2s\tremaining: 3m 2s\n",
      "170:\tlearn: 0.2317415\ttotal: 37.6s\tremaining: 3m 2s\n",
      "172:\tlearn: 0.2303545\ttotal: 38s\tremaining: 3m 1s\n",
      "174:\tlearn: 0.2299202\ttotal: 38.4s\tremaining: 3m\n",
      "176:\tlearn: 0.2285399\ttotal: 38.8s\tremaining: 3m\n",
      "178:\tlearn: 0.2277272\ttotal: 39.2s\tremaining: 2m 59s\n",
      "180:\tlearn: 0.2264901\ttotal: 39.6s\tremaining: 2m 59s\n",
      "182:\tlearn: 0.2253992\ttotal: 40s\tremaining: 2m 58s\n",
      "184:\tlearn: 0.2244498\ttotal: 40.4s\tremaining: 2m 57s\n",
      "186:\tlearn: 0.2229610\ttotal: 40.8s\tremaining: 2m 57s\n",
      "188:\tlearn: 0.2220833\ttotal: 41.2s\tremaining: 2m 56s\n",
      "190:\tlearn: 0.2201050\ttotal: 41.6s\tremaining: 2m 56s\n",
      "192:\tlearn: 0.2198258\ttotal: 42s\tremaining: 2m 55s\n",
      "194:\tlearn: 0.2187073\ttotal: 42.4s\tremaining: 2m 55s\n",
      "196:\tlearn: 0.2175265\ttotal: 42.8s\tremaining: 2m 54s\n",
      "198:\tlearn: 0.2171791\ttotal: 43.1s\tremaining: 2m 53s\n",
      "200:\tlearn: 0.2153377\ttotal: 43.6s\tremaining: 2m 53s\n",
      "202:\tlearn: 0.2143578\ttotal: 43.9s\tremaining: 2m 52s\n",
      "204:\tlearn: 0.2140080\ttotal: 44.3s\tremaining: 2m 51s\n",
      "206:\tlearn: 0.2137960\ttotal: 44.6s\tremaining: 2m 50s\n",
      "208:\tlearn: 0.2124804\ttotal: 45s\tremaining: 2m 50s\n",
      "210:\tlearn: 0.2114095\ttotal: 45.4s\tremaining: 2m 49s\n",
      "212:\tlearn: 0.2101892\ttotal: 45.8s\tremaining: 2m 49s\n",
      "214:\tlearn: 0.2096682\ttotal: 46.1s\tremaining: 2m 48s\n",
      "216:\tlearn: 0.2081523\ttotal: 46.5s\tremaining: 2m 47s\n",
      "218:\tlearn: 0.2077989\ttotal: 46.9s\tremaining: 2m 47s\n",
      "220:\tlearn: 0.2071558\ttotal: 47.2s\tremaining: 2m 46s\n",
      "222:\tlearn: 0.2063437\ttotal: 47.6s\tremaining: 2m 45s\n",
      "224:\tlearn: 0.2060310\ttotal: 47.9s\tremaining: 2m 45s\n",
      "226:\tlearn: 0.2052030\ttotal: 48.3s\tremaining: 2m 44s\n",
      "228:\tlearn: 0.2042256\ttotal: 48.7s\tremaining: 2m 44s\n",
      "230:\tlearn: 0.2037950\ttotal: 49.1s\tremaining: 2m 43s\n",
      "232:\tlearn: 0.2037867\ttotal: 49.4s\tremaining: 2m 42s\n",
      "234:\tlearn: 0.2033549\ttotal: 49.8s\tremaining: 2m 42s\n",
      "236:\tlearn: 0.2029912\ttotal: 50.1s\tremaining: 2m 41s\n",
      "238:\tlearn: 0.2028545\ttotal: 50.4s\tremaining: 2m 40s\n",
      "240:\tlearn: 0.2025946\ttotal: 50.8s\tremaining: 2m 39s\n",
      "242:\tlearn: 0.2011575\ttotal: 51.2s\tremaining: 2m 39s\n",
      "244:\tlearn: 0.2001163\ttotal: 51.6s\tremaining: 2m 38s\n",
      "246:\tlearn: 0.2000369\ttotal: 51.9s\tremaining: 2m 38s\n",
      "248:\tlearn: 0.1996203\ttotal: 52.3s\tremaining: 2m 37s\n",
      "250:\tlearn: 0.1992456\ttotal: 52.6s\tremaining: 2m 36s\n",
      "252:\tlearn: 0.1985856\ttotal: 53s\tremaining: 2m 36s\n",
      "254:\tlearn: 0.1980897\ttotal: 53.3s\tremaining: 2m 35s\n",
      "256:\tlearn: 0.1978338\ttotal: 53.7s\tremaining: 2m 35s\n",
      "258:\tlearn: 0.1975598\ttotal: 54s\tremaining: 2m 34s\n",
      "260:\tlearn: 0.1967532\ttotal: 54.4s\tremaining: 2m 34s\n",
      "262:\tlearn: 0.1961383\ttotal: 54.9s\tremaining: 2m 33s\n",
      "264:\tlearn: 0.1956176\ttotal: 55.2s\tremaining: 2m 33s\n",
      "266:\tlearn: 0.1945266\ttotal: 55.6s\tremaining: 2m 32s\n",
      "268:\tlearn: 0.1937881\ttotal: 56s\tremaining: 2m 32s\n",
      "270:\tlearn: 0.1928669\ttotal: 56.4s\tremaining: 2m 31s\n",
      "272:\tlearn: 0.1916273\ttotal: 56.8s\tremaining: 2m 31s\n",
      "274:\tlearn: 0.1913534\ttotal: 57.1s\tremaining: 2m 30s\n",
      "276:\tlearn: 0.1899788\ttotal: 57.5s\tremaining: 2m 30s\n",
      "278:\tlearn: 0.1894378\ttotal: 57.9s\tremaining: 2m 29s\n",
      "280:\tlearn: 0.1891141\ttotal: 58.3s\tremaining: 2m 29s\n",
      "282:\tlearn: 0.1888467\ttotal: 58.6s\tremaining: 2m 28s\n",
      "284:\tlearn: 0.1883351\ttotal: 59s\tremaining: 2m 28s\n",
      "286:\tlearn: 0.1879953\ttotal: 59.4s\tremaining: 2m 27s\n",
      "288:\tlearn: 0.1878087\ttotal: 59.8s\tremaining: 2m 27s\n",
      "290:\tlearn: 0.1873069\ttotal: 1m\tremaining: 2m 26s\n",
      "292:\tlearn: 0.1871016\ttotal: 1m\tremaining: 2m 25s\n",
      "294:\tlearn: 0.1861055\ttotal: 1m\tremaining: 2m 25s\n",
      "296:\tlearn: 0.1854323\ttotal: 1m 1s\tremaining: 2m 25s\n",
      "298:\tlearn: 0.1847052\ttotal: 1m 1s\tremaining: 2m 24s\n",
      "300:\tlearn: 0.1844950\ttotal: 1m 2s\tremaining: 2m 24s\n",
      "302:\tlearn: 0.1841090\ttotal: 1m 2s\tremaining: 2m 23s\n",
      "304:\tlearn: 0.1838497\ttotal: 1m 2s\tremaining: 2m 23s\n",
      "306:\tlearn: 0.1826924\ttotal: 1m 3s\tremaining: 2m 22s\n",
      "308:\tlearn: 0.1823176\ttotal: 1m 3s\tremaining: 2m 22s\n",
      "310:\tlearn: 0.1818911\ttotal: 1m 3s\tremaining: 2m 21s\n",
      "312:\tlearn: 0.1818827\ttotal: 1m 4s\tremaining: 2m 21s\n",
      "314:\tlearn: 0.1817029\ttotal: 1m 4s\tremaining: 2m 20s\n",
      "316:\tlearn: 0.1813077\ttotal: 1m 4s\tremaining: 2m 19s\n",
      "318:\tlearn: 0.1811772\ttotal: 1m 5s\tremaining: 2m 19s\n",
      "320:\tlearn: 0.1811015\ttotal: 1m 5s\tremaining: 2m 18s\n",
      "322:\tlearn: 0.1809082\ttotal: 1m 6s\tremaining: 2m 18s\n",
      "324:\tlearn: 0.1803608\ttotal: 1m 6s\tremaining: 2m 18s\n",
      "326:\tlearn: 0.1800011\ttotal: 1m 6s\tremaining: 2m 17s\n",
      "328:\tlearn: 0.1797729\ttotal: 1m 7s\tremaining: 2m 17s\n",
      "330:\tlearn: 0.1794240\ttotal: 1m 7s\tremaining: 2m 16s\n",
      "332:\tlearn: 0.1786908\ttotal: 1m 8s\tremaining: 2m 16s\n",
      "334:\tlearn: 0.1785320\ttotal: 1m 8s\tremaining: 2m 15s\n",
      "336:\tlearn: 0.1783326\ttotal: 1m 8s\tremaining: 2m 15s\n",
      "338:\tlearn: 0.1781994\ttotal: 1m 9s\tremaining: 2m 14s\n",
      "340:\tlearn: 0.1773484\ttotal: 1m 9s\tremaining: 2m 14s\n",
      "342:\tlearn: 0.1768400\ttotal: 1m 9s\tremaining: 2m 14s\n",
      "344:\tlearn: 0.1766517\ttotal: 1m 10s\tremaining: 2m 13s\n",
      "346:\tlearn: 0.1766439\ttotal: 1m 10s\tremaining: 2m 13s\n",
      "348:\tlearn: 0.1764560\ttotal: 1m 11s\tremaining: 2m 12s\n",
      "350:\tlearn: 0.1761893\ttotal: 1m 11s\tremaining: 2m 12s\n",
      "352:\tlearn: 0.1761048\ttotal: 1m 11s\tremaining: 2m 11s\n",
      "354:\tlearn: 0.1757659\ttotal: 1m 12s\tremaining: 2m 11s\n",
      "356:\tlearn: 0.1755941\ttotal: 1m 12s\tremaining: 2m 10s\n",
      "358:\tlearn: 0.1754139\ttotal: 1m 12s\tremaining: 2m 10s\n",
      "360:\tlearn: 0.1749810\ttotal: 1m 13s\tremaining: 2m 9s\n",
      "362:\tlearn: 0.1745601\ttotal: 1m 13s\tremaining: 2m 9s\n",
      "364:\tlearn: 0.1738160\ttotal: 1m 13s\tremaining: 2m 8s\n",
      "366:\tlearn: 0.1736736\ttotal: 1m 14s\tremaining: 2m 8s\n",
      "368:\tlearn: 0.1735347\ttotal: 1m 14s\tremaining: 2m 7s\n",
      "370:\tlearn: 0.1725459\ttotal: 1m 15s\tremaining: 2m 7s\n",
      "372:\tlearn: 0.1718324\ttotal: 1m 15s\tremaining: 2m 6s\n",
      "374:\tlearn: 0.1715172\ttotal: 1m 15s\tremaining: 2m 6s\n",
      "376:\tlearn: 0.1713348\ttotal: 1m 16s\tremaining: 2m 5s\n",
      "378:\tlearn: 0.1712140\ttotal: 1m 16s\tremaining: 2m 5s\n",
      "380:\tlearn: 0.1709176\ttotal: 1m 16s\tremaining: 2m 4s\n",
      "382:\tlearn: 0.1708392\ttotal: 1m 17s\tremaining: 2m 4s\n",
      "384:\tlearn: 0.1705380\ttotal: 1m 17s\tremaining: 2m 4s\n",
      "386:\tlearn: 0.1703409\ttotal: 1m 18s\tremaining: 2m 3s\n",
      "388:\tlearn: 0.1702618\ttotal: 1m 18s\tremaining: 2m 3s\n",
      "390:\tlearn: 0.1698322\ttotal: 1m 18s\tremaining: 2m 2s\n",
      "392:\tlearn: 0.1694415\ttotal: 1m 19s\tremaining: 2m 2s\n",
      "394:\tlearn: 0.1691045\ttotal: 1m 19s\tremaining: 2m 1s\n",
      "396:\tlearn: 0.1687976\ttotal: 1m 19s\tremaining: 2m 1s\n",
      "398:\tlearn: 0.1682418\ttotal: 1m 20s\tremaining: 2m\n",
      "400:\tlearn: 0.1678827\ttotal: 1m 20s\tremaining: 2m\n",
      "402:\tlearn: 0.1678447\ttotal: 1m 20s\tremaining: 1m 59s\n",
      "404:\tlearn: 0.1677309\ttotal: 1m 21s\tremaining: 1m 59s\n",
      "406:\tlearn: 0.1676769\ttotal: 1m 21s\tremaining: 1m 58s\n",
      "408:\tlearn: 0.1673390\ttotal: 1m 22s\tremaining: 1m 58s\n",
      "410:\tlearn: 0.1672799\ttotal: 1m 22s\tremaining: 1m 58s\n",
      "412:\tlearn: 0.1672019\ttotal: 1m 22s\tremaining: 1m 57s\n",
      "414:\tlearn: 0.1670584\ttotal: 1m 23s\tremaining: 1m 57s\n",
      "416:\tlearn: 0.1663564\ttotal: 1m 23s\tremaining: 1m 56s\n",
      "418:\tlearn: 0.1659538\ttotal: 1m 23s\tremaining: 1m 56s\n",
      "420:\tlearn: 0.1653978\ttotal: 1m 24s\tremaining: 1m 55s\n",
      "422:\tlearn: 0.1653233\ttotal: 1m 24s\tremaining: 1m 55s\n",
      "424:\tlearn: 0.1652241\ttotal: 1m 24s\tremaining: 1m 54s\n",
      "426:\tlearn: 0.1649861\ttotal: 1m 25s\tremaining: 1m 54s\n",
      "428:\tlearn: 0.1646214\ttotal: 1m 25s\tremaining: 1m 54s\n",
      "430:\tlearn: 0.1643653\ttotal: 1m 26s\tremaining: 1m 53s\n",
      "432:\tlearn: 0.1642423\ttotal: 1m 26s\tremaining: 1m 53s\n",
      "434:\tlearn: 0.1641531\ttotal: 1m 26s\tremaining: 1m 52s\n",
      "436:\tlearn: 0.1639995\ttotal: 1m 27s\tremaining: 1m 52s\n",
      "438:\tlearn: 0.1639310\ttotal: 1m 27s\tremaining: 1m 51s\n",
      "440:\tlearn: 0.1636933\ttotal: 1m 27s\tremaining: 1m 51s\n",
      "442:\tlearn: 0.1634371\ttotal: 1m 28s\tremaining: 1m 50s\n",
      "444:\tlearn: 0.1633882\ttotal: 1m 28s\tremaining: 1m 50s\n",
      "446:\tlearn: 0.1632654\ttotal: 1m 28s\tremaining: 1m 49s\n",
      "448:\tlearn: 0.1629791\ttotal: 1m 29s\tremaining: 1m 49s\n",
      "450:\tlearn: 0.1627404\ttotal: 1m 29s\tremaining: 1m 49s\n",
      "452:\tlearn: 0.1625388\ttotal: 1m 30s\tremaining: 1m 48s\n",
      "454:\tlearn: 0.1624629\ttotal: 1m 30s\tremaining: 1m 48s\n",
      "456:\tlearn: 0.1623071\ttotal: 1m 30s\tremaining: 1m 47s\n",
      "458:\tlearn: 0.1621632\ttotal: 1m 31s\tremaining: 1m 47s\n",
      "460:\tlearn: 0.1617623\ttotal: 1m 31s\tremaining: 1m 46s\n",
      "462:\tlearn: 0.1613377\ttotal: 1m 31s\tremaining: 1m 46s\n",
      "464:\tlearn: 0.1610776\ttotal: 1m 32s\tremaining: 1m 46s\n",
      "466:\tlearn: 0.1604579\ttotal: 1m 32s\tremaining: 1m 45s\n",
      "468:\tlearn: 0.1603529\ttotal: 1m 32s\tremaining: 1m 45s\n",
      "470:\tlearn: 0.1602296\ttotal: 1m 33s\tremaining: 1m 44s\n",
      "472:\tlearn: 0.1599173\ttotal: 1m 33s\tremaining: 1m 44s\n",
      "474:\tlearn: 0.1597024\ttotal: 1m 34s\tremaining: 1m 43s\n",
      "476:\tlearn: 0.1596482\ttotal: 1m 34s\tremaining: 1m 43s\n",
      "478:\tlearn: 0.1592103\ttotal: 1m 34s\tremaining: 1m 43s\n",
      "480:\tlearn: 0.1592046\ttotal: 1m 35s\tremaining: 1m 42s\n",
      "482:\tlearn: 0.1583960\ttotal: 1m 35s\tremaining: 1m 42s\n",
      "484:\tlearn: 0.1577217\ttotal: 1m 35s\tremaining: 1m 41s\n",
      "486:\tlearn: 0.1576013\ttotal: 1m 36s\tremaining: 1m 41s\n",
      "488:\tlearn: 0.1575309\ttotal: 1m 36s\tremaining: 1m 40s\n",
      "490:\tlearn: 0.1569946\ttotal: 1m 36s\tremaining: 1m 40s\n",
      "492:\tlearn: 0.1568267\ttotal: 1m 37s\tremaining: 1m 40s\n",
      "494:\tlearn: 0.1566513\ttotal: 1m 37s\tremaining: 1m 39s\n",
      "496:\tlearn: 0.1556181\ttotal: 1m 38s\tremaining: 1m 39s\n",
      "498:\tlearn: 0.1553693\ttotal: 1m 38s\tremaining: 1m 38s\n",
      "500:\tlearn: 0.1549261\ttotal: 1m 38s\tremaining: 1m 38s\n",
      "502:\tlearn: 0.1548211\ttotal: 1m 39s\tremaining: 1m 38s\n",
      "504:\tlearn: 0.1547612\ttotal: 1m 39s\tremaining: 1m 37s\n",
      "506:\tlearn: 0.1545116\ttotal: 1m 40s\tremaining: 1m 37s\n",
      "508:\tlearn: 0.1543683\ttotal: 1m 40s\tremaining: 1m 36s\n",
      "510:\tlearn: 0.1542277\ttotal: 1m 40s\tremaining: 1m 36s\n",
      "512:\tlearn: 0.1541580\ttotal: 1m 41s\tremaining: 1m 35s\n",
      "514:\tlearn: 0.1540484\ttotal: 1m 41s\tremaining: 1m 35s\n",
      "516:\tlearn: 0.1539493\ttotal: 1m 41s\tremaining: 1m 35s\n",
      "518:\tlearn: 0.1535494\ttotal: 1m 42s\tremaining: 1m 34s\n",
      "520:\tlearn: 0.1530448\ttotal: 1m 42s\tremaining: 1m 34s\n",
      "522:\tlearn: 0.1529424\ttotal: 1m 43s\tremaining: 1m 33s\n",
      "524:\tlearn: 0.1527800\ttotal: 1m 43s\tremaining: 1m 33s\n",
      "526:\tlearn: 0.1527238\ttotal: 1m 43s\tremaining: 1m 33s\n",
      "528:\tlearn: 0.1519449\ttotal: 1m 44s\tremaining: 1m 32s\n",
      "530:\tlearn: 0.1517824\ttotal: 1m 44s\tremaining: 1m 32s\n",
      "532:\tlearn: 0.1515124\ttotal: 1m 44s\tremaining: 1m 31s\n",
      "534:\tlearn: 0.1512021\ttotal: 1m 45s\tremaining: 1m 31s\n",
      "536:\tlearn: 0.1509946\ttotal: 1m 45s\tremaining: 1m 31s\n",
      "538:\tlearn: 0.1506063\ttotal: 1m 45s\tremaining: 1m 30s\n",
      "540:\tlearn: 0.1505596\ttotal: 1m 46s\tremaining: 1m 30s\n",
      "542:\tlearn: 0.1502999\ttotal: 1m 46s\tremaining: 1m 29s\n",
      "544:\tlearn: 0.1499276\ttotal: 1m 47s\tremaining: 1m 29s\n",
      "546:\tlearn: 0.1498592\ttotal: 1m 47s\tremaining: 1m 28s\n",
      "548:\tlearn: 0.1494967\ttotal: 1m 47s\tremaining: 1m 28s\n",
      "550:\tlearn: 0.1493893\ttotal: 1m 48s\tremaining: 1m 28s\n",
      "552:\tlearn: 0.1492540\ttotal: 1m 48s\tremaining: 1m 27s\n",
      "554:\tlearn: 0.1490293\ttotal: 1m 48s\tremaining: 1m 27s\n",
      "556:\tlearn: 0.1489561\ttotal: 1m 49s\tremaining: 1m 26s\n",
      "558:\tlearn: 0.1488558\ttotal: 1m 49s\tremaining: 1m 26s\n",
      "560:\tlearn: 0.1485968\ttotal: 1m 49s\tremaining: 1m 26s\n",
      "562:\tlearn: 0.1484032\ttotal: 1m 50s\tremaining: 1m 25s\n",
      "564:\tlearn: 0.1482377\ttotal: 1m 50s\tremaining: 1m 25s\n",
      "566:\tlearn: 0.1481587\ttotal: 1m 51s\tremaining: 1m 24s\n",
      "568:\tlearn: 0.1480882\ttotal: 1m 51s\tremaining: 1m 24s\n",
      "570:\tlearn: 0.1479779\ttotal: 1m 51s\tremaining: 1m 23s\n",
      "572:\tlearn: 0.1478851\ttotal: 1m 52s\tremaining: 1m 23s\n",
      "574:\tlearn: 0.1477428\ttotal: 1m 52s\tremaining: 1m 23s\n",
      "576:\tlearn: 0.1476337\ttotal: 1m 52s\tremaining: 1m 22s\n",
      "578:\tlearn: 0.1475013\ttotal: 1m 53s\tremaining: 1m 22s\n",
      "580:\tlearn: 0.1473873\ttotal: 1m 53s\tremaining: 1m 21s\n",
      "582:\tlearn: 0.1471303\ttotal: 1m 53s\tremaining: 1m 21s\n",
      "584:\tlearn: 0.1469702\ttotal: 1m 54s\tremaining: 1m 21s\n",
      "586:\tlearn: 0.1466759\ttotal: 1m 54s\tremaining: 1m 20s\n",
      "588:\tlearn: 0.1464904\ttotal: 1m 54s\tremaining: 1m 20s\n",
      "590:\tlearn: 0.1462161\ttotal: 1m 55s\tremaining: 1m 19s\n",
      "592:\tlearn: 0.1460324\ttotal: 1m 55s\tremaining: 1m 19s\n",
      "594:\tlearn: 0.1459259\ttotal: 1m 56s\tremaining: 1m 18s\n",
      "596:\tlearn: 0.1458561\ttotal: 1m 56s\tremaining: 1m 18s\n",
      "598:\tlearn: 0.1457843\ttotal: 1m 56s\tremaining: 1m 18s\n",
      "600:\tlearn: 0.1455065\ttotal: 1m 57s\tremaining: 1m 17s\n",
      "602:\tlearn: 0.1453567\ttotal: 1m 57s\tremaining: 1m 17s\n",
      "604:\tlearn: 0.1452916\ttotal: 1m 57s\tremaining: 1m 16s\n",
      "606:\tlearn: 0.1450305\ttotal: 1m 58s\tremaining: 1m 16s\n",
      "608:\tlearn: 0.1449707\ttotal: 1m 58s\tremaining: 1m 16s\n",
      "610:\tlearn: 0.1449649\ttotal: 1m 58s\tremaining: 1m 15s\n",
      "612:\tlearn: 0.1449549\ttotal: 1m 59s\tremaining: 1m 15s\n",
      "614:\tlearn: 0.1444614\ttotal: 1m 59s\tremaining: 1m 14s\n",
      "616:\tlearn: 0.1442969\ttotal: 1m 59s\tremaining: 1m 14s\n",
      "618:\tlearn: 0.1440965\ttotal: 2m\tremaining: 1m 14s\n",
      "620:\tlearn: 0.1439163\ttotal: 2m\tremaining: 1m 13s\n",
      "622:\tlearn: 0.1437460\ttotal: 2m 1s\tremaining: 1m 13s\n",
      "624:\tlearn: 0.1435459\ttotal: 2m 1s\tremaining: 1m 12s\n",
      "626:\tlearn: 0.1432202\ttotal: 2m 1s\tremaining: 1m 12s\n",
      "628:\tlearn: 0.1430339\ttotal: 2m 2s\tremaining: 1m 12s\n",
      "630:\tlearn: 0.1428063\ttotal: 2m 2s\tremaining: 1m 11s\n",
      "632:\tlearn: 0.1426756\ttotal: 2m 2s\tremaining: 1m 11s\n",
      "634:\tlearn: 0.1426230\ttotal: 2m 3s\tremaining: 1m 10s\n",
      "636:\tlearn: 0.1425267\ttotal: 2m 3s\tremaining: 1m 10s\n",
      "638:\tlearn: 0.1424477\ttotal: 2m 3s\tremaining: 1m 10s\n",
      "640:\tlearn: 0.1422299\ttotal: 2m 4s\tremaining: 1m 9s\n",
      "642:\tlearn: 0.1421416\ttotal: 2m 4s\tremaining: 1m 9s\n",
      "644:\tlearn: 0.1419814\ttotal: 2m 5s\tremaining: 1m 8s\n",
      "646:\tlearn: 0.1418534\ttotal: 2m 5s\tremaining: 1m 8s\n",
      "648:\tlearn: 0.1415520\ttotal: 2m 5s\tremaining: 1m 8s\n",
      "650:\tlearn: 0.1414706\ttotal: 2m 6s\tremaining: 1m 7s\n",
      "652:\tlearn: 0.1414020\ttotal: 2m 6s\tremaining: 1m 7s\n",
      "654:\tlearn: 0.1408873\ttotal: 2m 7s\tremaining: 1m 6s\n",
      "656:\tlearn: 0.1407965\ttotal: 2m 7s\tremaining: 1m 6s\n",
      "658:\tlearn: 0.1407494\ttotal: 2m 7s\tremaining: 1m 6s\n",
      "660:\tlearn: 0.1406107\ttotal: 2m 8s\tremaining: 1m 5s\n",
      "662:\tlearn: 0.1405583\ttotal: 2m 8s\tremaining: 1m 5s\n",
      "664:\tlearn: 0.1405032\ttotal: 2m 8s\tremaining: 1m 4s\n",
      "666:\tlearn: 0.1402278\ttotal: 2m 9s\tremaining: 1m 4s\n",
      "668:\tlearn: 0.1400684\ttotal: 2m 9s\tremaining: 1m 4s\n",
      "670:\tlearn: 0.1399773\ttotal: 2m 10s\tremaining: 1m 3s\n",
      "672:\tlearn: 0.1398835\ttotal: 2m 10s\tremaining: 1m 3s\n",
      "674:\tlearn: 0.1397984\ttotal: 2m 10s\tremaining: 1m 2s\n",
      "676:\tlearn: 0.1396783\ttotal: 2m 11s\tremaining: 1m 2s\n",
      "678:\tlearn: 0.1394995\ttotal: 2m 11s\tremaining: 1m 2s\n",
      "680:\tlearn: 0.1393178\ttotal: 2m 11s\tremaining: 1m 1s\n",
      "682:\tlearn: 0.1392259\ttotal: 2m 12s\tremaining: 1m 1s\n",
      "684:\tlearn: 0.1390315\ttotal: 2m 12s\tremaining: 1m\n",
      "686:\tlearn: 0.1386256\ttotal: 2m 12s\tremaining: 1m\n",
      "688:\tlearn: 0.1384845\ttotal: 2m 13s\tremaining: 1m\n",
      "690:\tlearn: 0.1384103\ttotal: 2m 13s\tremaining: 59.8s\n",
      "692:\tlearn: 0.1383596\ttotal: 2m 14s\tremaining: 59.4s\n",
      "694:\tlearn: 0.1382498\ttotal: 2m 14s\tremaining: 59s\n",
      "696:\tlearn: 0.1381839\ttotal: 2m 14s\tremaining: 58.6s\n",
      "698:\tlearn: 0.1378452\ttotal: 2m 15s\tremaining: 58.2s\n",
      "700:\tlearn: 0.1376415\ttotal: 2m 15s\tremaining: 57.8s\n",
      "702:\tlearn: 0.1375951\ttotal: 2m 15s\tremaining: 57.4s\n",
      "704:\tlearn: 0.1373495\ttotal: 2m 16s\tremaining: 57s\n",
      "706:\tlearn: 0.1371441\ttotal: 2m 16s\tremaining: 56.6s\n",
      "708:\tlearn: 0.1370113\ttotal: 2m 17s\tremaining: 56.2s\n",
      "710:\tlearn: 0.1369760\ttotal: 2m 17s\tremaining: 55.8s\n",
      "712:\tlearn: 0.1368132\ttotal: 2m 17s\tremaining: 55.4s\n",
      "714:\tlearn: 0.1367404\ttotal: 2m 18s\tremaining: 55s\n",
      "716:\tlearn: 0.1366710\ttotal: 2m 18s\tremaining: 54.6s\n",
      "718:\tlearn: 0.1365279\ttotal: 2m 18s\tremaining: 54.2s\n",
      "720:\tlearn: 0.1363978\ttotal: 2m 19s\tremaining: 53.8s\n",
      "722:\tlearn: 0.1363461\ttotal: 2m 19s\tremaining: 53.4s\n",
      "724:\tlearn: 0.1362878\ttotal: 2m 19s\tremaining: 53s\n",
      "726:\tlearn: 0.1362341\ttotal: 2m 20s\tremaining: 52.6s\n",
      "728:\tlearn: 0.1362310\ttotal: 2m 20s\tremaining: 52.2s\n",
      "730:\tlearn: 0.1361497\ttotal: 2m 20s\tremaining: 51.9s\n",
      "732:\tlearn: 0.1360300\ttotal: 2m 21s\tremaining: 51.5s\n",
      "734:\tlearn: 0.1359724\ttotal: 2m 21s\tremaining: 51.1s\n",
      "736:\tlearn: 0.1358804\ttotal: 2m 21s\tremaining: 50.7s\n",
      "738:\tlearn: 0.1358749\ttotal: 2m 22s\tremaining: 50.3s\n",
      "740:\tlearn: 0.1357226\ttotal: 2m 22s\tremaining: 49.9s\n",
      "742:\tlearn: 0.1354905\ttotal: 2m 23s\tremaining: 49.5s\n",
      "744:\tlearn: 0.1354373\ttotal: 2m 23s\tremaining: 49.1s\n",
      "746:\tlearn: 0.1353721\ttotal: 2m 23s\tremaining: 48.7s\n",
      "748:\tlearn: 0.1351620\ttotal: 2m 24s\tremaining: 48.3s\n",
      "750:\tlearn: 0.1351102\ttotal: 2m 24s\tremaining: 47.9s\n",
      "752:\tlearn: 0.1351052\ttotal: 2m 24s\tremaining: 47.5s\n",
      "754:\tlearn: 0.1350487\ttotal: 2m 25s\tremaining: 47.1s\n",
      "756:\tlearn: 0.1348921\ttotal: 2m 25s\tremaining: 46.7s\n",
      "758:\tlearn: 0.1347975\ttotal: 2m 25s\tremaining: 46.3s\n",
      "760:\tlearn: 0.1347587\ttotal: 2m 26s\tremaining: 45.9s\n",
      "762:\tlearn: 0.1346857\ttotal: 2m 26s\tremaining: 45.5s\n",
      "764:\tlearn: 0.1345512\ttotal: 2m 26s\tremaining: 45.1s\n",
      "766:\tlearn: 0.1344811\ttotal: 2m 27s\tremaining: 44.7s\n",
      "768:\tlearn: 0.1343678\ttotal: 2m 27s\tremaining: 44.3s\n",
      "770:\tlearn: 0.1343224\ttotal: 2m 27s\tremaining: 44s\n",
      "772:\tlearn: 0.1342171\ttotal: 2m 28s\tremaining: 43.6s\n",
      "774:\tlearn: 0.1341452\ttotal: 2m 28s\tremaining: 43.2s\n",
      "776:\tlearn: 0.1340725\ttotal: 2m 29s\tremaining: 42.8s\n",
      "778:\tlearn: 0.1339139\ttotal: 2m 29s\tremaining: 42.4s\n",
      "780:\tlearn: 0.1338758\ttotal: 2m 29s\tremaining: 42s\n",
      "782:\tlearn: 0.1338464\ttotal: 2m 30s\tremaining: 41.6s\n",
      "784:\tlearn: 0.1337827\ttotal: 2m 30s\tremaining: 41.3s\n",
      "786:\tlearn: 0.1337176\ttotal: 2m 30s\tremaining: 40.9s\n",
      "788:\tlearn: 0.1335301\ttotal: 2m 31s\tremaining: 40.5s\n",
      "790:\tlearn: 0.1333852\ttotal: 2m 31s\tremaining: 40.1s\n",
      "792:\tlearn: 0.1333157\ttotal: 2m 32s\tremaining: 39.7s\n",
      "794:\tlearn: 0.1331061\ttotal: 2m 32s\tremaining: 39.3s\n",
      "796:\tlearn: 0.1328831\ttotal: 2m 32s\tremaining: 38.9s\n",
      "798:\tlearn: 0.1328464\ttotal: 2m 33s\tremaining: 38.5s\n",
      "800:\tlearn: 0.1328152\ttotal: 2m 33s\tremaining: 38.2s\n",
      "802:\tlearn: 0.1327928\ttotal: 2m 33s\tremaining: 37.8s\n",
      "804:\tlearn: 0.1325994\ttotal: 2m 34s\tremaining: 37.4s\n",
      "806:\tlearn: 0.1323771\ttotal: 2m 34s\tremaining: 37s\n",
      "808:\tlearn: 0.1321883\ttotal: 2m 35s\tremaining: 36.6s\n",
      "810:\tlearn: 0.1320257\ttotal: 2m 35s\tremaining: 36.2s\n",
      "812:\tlearn: 0.1319785\ttotal: 2m 35s\tremaining: 35.8s\n",
      "814:\tlearn: 0.1319213\ttotal: 2m 36s\tremaining: 35.4s\n",
      "816:\tlearn: 0.1318728\ttotal: 2m 36s\tremaining: 35s\n",
      "818:\tlearn: 0.1316674\ttotal: 2m 36s\tremaining: 34.7s\n",
      "820:\tlearn: 0.1315911\ttotal: 2m 37s\tremaining: 34.3s\n",
      "822:\tlearn: 0.1314382\ttotal: 2m 37s\tremaining: 33.9s\n",
      "824:\tlearn: 0.1313825\ttotal: 2m 37s\tremaining: 33.5s\n",
      "826:\tlearn: 0.1313394\ttotal: 2m 38s\tremaining: 33.1s\n",
      "828:\tlearn: 0.1311559\ttotal: 2m 38s\tremaining: 32.7s\n",
      "830:\tlearn: 0.1309205\ttotal: 2m 39s\tremaining: 32.3s\n",
      "832:\tlearn: 0.1308370\ttotal: 2m 39s\tremaining: 32s\n",
      "834:\tlearn: 0.1307744\ttotal: 2m 39s\tremaining: 31.6s\n",
      "836:\tlearn: 0.1307329\ttotal: 2m 40s\tremaining: 31.2s\n",
      "838:\tlearn: 0.1304866\ttotal: 2m 40s\tremaining: 30.8s\n",
      "840:\tlearn: 0.1304134\ttotal: 2m 40s\tremaining: 30.4s\n",
      "842:\tlearn: 0.1302322\ttotal: 2m 41s\tremaining: 30s\n",
      "844:\tlearn: 0.1301314\ttotal: 2m 41s\tremaining: 29.6s\n",
      "846:\tlearn: 0.1300925\ttotal: 2m 41s\tremaining: 29.3s\n",
      "848:\tlearn: 0.1300155\ttotal: 2m 42s\tremaining: 28.9s\n",
      "850:\tlearn: 0.1299525\ttotal: 2m 42s\tremaining: 28.5s\n",
      "852:\tlearn: 0.1298611\ttotal: 2m 43s\tremaining: 28.1s\n",
      "854:\tlearn: 0.1296619\ttotal: 2m 43s\tremaining: 27.7s\n",
      "856:\tlearn: 0.1294818\ttotal: 2m 43s\tremaining: 27.3s\n",
      "858:\tlearn: 0.1294309\ttotal: 2m 44s\tremaining: 26.9s\n",
      "860:\tlearn: 0.1294091\ttotal: 2m 44s\tremaining: 26.6s\n",
      "862:\tlearn: 0.1293254\ttotal: 2m 44s\tremaining: 26.2s\n",
      "864:\tlearn: 0.1292284\ttotal: 2m 45s\tremaining: 25.8s\n",
      "866:\tlearn: 0.1290561\ttotal: 2m 45s\tremaining: 25.4s\n",
      "868:\tlearn: 0.1289244\ttotal: 2m 45s\tremaining: 25s\n",
      "870:\tlearn: 0.1288019\ttotal: 2m 46s\tremaining: 24.6s\n",
      "872:\tlearn: 0.1287229\ttotal: 2m 46s\tremaining: 24.2s\n",
      "874:\tlearn: 0.1286365\ttotal: 2m 46s\tremaining: 23.9s\n",
      "876:\tlearn: 0.1278057\ttotal: 2m 47s\tremaining: 23.5s\n",
      "878:\tlearn: 0.1277544\ttotal: 2m 47s\tremaining: 23.1s\n",
      "880:\tlearn: 0.1277052\ttotal: 2m 48s\tremaining: 22.7s\n",
      "882:\tlearn: 0.1276694\ttotal: 2m 48s\tremaining: 22.3s\n",
      "884:\tlearn: 0.1275663\ttotal: 2m 48s\tremaining: 21.9s\n",
      "886:\tlearn: 0.1275362\ttotal: 2m 49s\tremaining: 21.5s\n",
      "888:\tlearn: 0.1272641\ttotal: 2m 49s\tremaining: 21.2s\n",
      "890:\tlearn: 0.1270946\ttotal: 2m 49s\tremaining: 20.8s\n",
      "892:\tlearn: 0.1269271\ttotal: 2m 50s\tremaining: 20.4s\n",
      "894:\tlearn: 0.1268096\ttotal: 2m 50s\tremaining: 20s\n",
      "896:\tlearn: 0.1267469\ttotal: 2m 50s\tremaining: 19.6s\n",
      "898:\tlearn: 0.1266657\ttotal: 2m 51s\tremaining: 19.2s\n",
      "900:\tlearn: 0.1266195\ttotal: 2m 51s\tremaining: 18.9s\n",
      "902:\tlearn: 0.1265958\ttotal: 2m 52s\tremaining: 18.5s\n",
      "904:\tlearn: 0.1265082\ttotal: 2m 52s\tremaining: 18.1s\n",
      "906:\tlearn: 0.1264475\ttotal: 2m 52s\tremaining: 17.7s\n",
      "908:\tlearn: 0.1262518\ttotal: 2m 53s\tremaining: 17.3s\n",
      "910:\tlearn: 0.1260741\ttotal: 2m 53s\tremaining: 16.9s\n",
      "912:\tlearn: 0.1258540\ttotal: 2m 53s\tremaining: 16.6s\n",
      "914:\tlearn: 0.1256108\ttotal: 2m 54s\tremaining: 16.2s\n",
      "916:\tlearn: 0.1255400\ttotal: 2m 54s\tremaining: 15.8s\n",
      "918:\tlearn: 0.1254676\ttotal: 2m 54s\tremaining: 15.4s\n",
      "920:\tlearn: 0.1253267\ttotal: 2m 55s\tremaining: 15s\n",
      "922:\tlearn: 0.1252301\ttotal: 2m 55s\tremaining: 14.7s\n",
      "924:\tlearn: 0.1249214\ttotal: 2m 56s\tremaining: 14.3s\n",
      "926:\tlearn: 0.1248841\ttotal: 2m 56s\tremaining: 13.9s\n",
      "928:\tlearn: 0.1247472\ttotal: 2m 56s\tremaining: 13.5s\n",
      "930:\tlearn: 0.1246782\ttotal: 2m 57s\tremaining: 13.1s\n",
      "932:\tlearn: 0.1245075\ttotal: 2m 57s\tremaining: 12.8s\n",
      "934:\tlearn: 0.1244083\ttotal: 2m 57s\tremaining: 12.4s\n",
      "936:\tlearn: 0.1239913\ttotal: 2m 58s\tremaining: 12s\n",
      "938:\tlearn: 0.1239527\ttotal: 2m 58s\tremaining: 11.6s\n",
      "940:\tlearn: 0.1238419\ttotal: 2m 59s\tremaining: 11.2s\n",
      "942:\tlearn: 0.1237539\ttotal: 2m 59s\tremaining: 10.8s\n",
      "944:\tlearn: 0.1235467\ttotal: 2m 59s\tremaining: 10.5s\n",
      "946:\tlearn: 0.1235206\ttotal: 3m\tremaining: 10.1s\n",
      "948:\tlearn: 0.1234301\ttotal: 3m\tremaining: 9.7s\n",
      "950:\tlearn: 0.1234263\ttotal: 3m\tremaining: 9.32s\n",
      "952:\tlearn: 0.1233305\ttotal: 3m 1s\tremaining: 8.94s\n",
      "954:\tlearn: 0.1232504\ttotal: 3m 1s\tremaining: 8.56s\n",
      "956:\tlearn: 0.1231168\ttotal: 3m 1s\tremaining: 8.18s\n",
      "958:\tlearn: 0.1229858\ttotal: 3m 2s\tremaining: 7.79s\n",
      "960:\tlearn: 0.1229677\ttotal: 3m 2s\tremaining: 7.41s\n",
      "962:\tlearn: 0.1227834\ttotal: 3m 3s\tremaining: 7.03s\n",
      "964:\tlearn: 0.1227643\ttotal: 3m 3s\tremaining: 6.65s\n",
      "966:\tlearn: 0.1226754\ttotal: 3m 3s\tremaining: 6.27s\n",
      "968:\tlearn: 0.1225968\ttotal: 3m 4s\tremaining: 5.89s\n",
      "970:\tlearn: 0.1225362\ttotal: 3m 4s\tremaining: 5.51s\n",
      "972:\tlearn: 0.1224048\ttotal: 3m 4s\tremaining: 5.13s\n",
      "974:\tlearn: 0.1223004\ttotal: 3m 5s\tremaining: 4.75s\n",
      "976:\tlearn: 0.1221501\ttotal: 3m 5s\tremaining: 4.37s\n",
      "978:\tlearn: 0.1215848\ttotal: 3m 5s\tremaining: 3.99s\n",
      "980:\tlearn: 0.1214886\ttotal: 3m 6s\tremaining: 3.61s\n",
      "982:\tlearn: 0.1210478\ttotal: 3m 6s\tremaining: 3.23s\n",
      "984:\tlearn: 0.1209924\ttotal: 3m 7s\tremaining: 2.85s\n",
      "986:\tlearn: 0.1209164\ttotal: 3m 7s\tremaining: 2.47s\n",
      "988:\tlearn: 0.1208639\ttotal: 3m 7s\tremaining: 2.09s\n",
      "990:\tlearn: 0.1208108\ttotal: 3m 8s\tremaining: 1.71s\n",
      "992:\tlearn: 0.1207535\ttotal: 3m 8s\tremaining: 1.33s\n",
      "994:\tlearn: 0.1205700\ttotal: 3m 9s\tremaining: 950ms\n",
      "996:\tlearn: 0.1204626\ttotal: 3m 9s\tremaining: 570ms\n",
      "998:\tlearn: 0.1203908\ttotal: 3m 9s\tremaining: 190ms\n",
      "999:\tlearn: 0.1203166\ttotal: 3m 10s\tremaining: 0us\n",
      "(      Metric     Value\n",
      "0   F1 Score  0.955067\n",
      "1  Precision  0.955089\n",
      "2     Recall  0.955119,      1    0    4    7    3    5    8    9    2    6\n",
      "1  808    0    3    1    2    3    5    0    4    1\n",
      "0    0  927    2    1    0    1    1    2    3    0\n",
      "4    2    2  789    8    9    1    2   11    9    2\n",
      "7    2    3   16  807    2   19    1    5    8    7\n",
      "3    1    2    4    0  774    0    5    2    6   20\n",
      "5    4    2    2    8    2  719   10    2    7    3\n",
      "8    3    2    1    0    0    6  812    0    3    0\n",
      "9    0    5    4    5    6    1    0  841    2   16\n",
      "2    4    6    4    9    0   12    4    1  762   11\n",
      "6    4    2    1    8   13    4    0   16    6  784)\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "catboost_classifier = CatBoostClassifier(iterations=1000, depth=4, learning_rate=0.1, verbose=2)\n",
    "catboost_classifier.fit(X_train_norm, y_train)\n",
    "\n",
    "y_pred = catboost_classifier.predict(X_valid_norm)\n",
    "\n",
    "catboost_classifier_assessement = evaluate_classifier(y_valid, y_pred)\n",
    "print(catboost_classifier_assessement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanncauchepin/Git/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-01 20:21:25.092408: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 105369600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7472 - loss: 0.8038 - val_accuracy: 0.9400 - val_loss: 0.2079\n",
      "Epoch 2/20\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9292 - loss: 0.2314 - val_accuracy: 0.9555 - val_loss: 0.1463\n",
      "Epoch 3/20\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9518 - loss: 0.1625 - val_accuracy: 0.9620 - val_loss: 0.1266\n",
      "Epoch 4/20\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.1356 - val_accuracy: 0.9646 - val_loss: 0.1170\n",
      "Epoch 5/20\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.1113 - val_accuracy: 0.9689 - val_loss: 0.1046\n",
      "Epoch 6/20\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9714 - loss: 0.0942 - val_accuracy: 0.9692 - val_loss: 0.1033\n",
      "Epoch 7/20\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9741 - loss: 0.0840 - val_accuracy: 0.9706 - val_loss: 0.1025\n",
      "Epoch 8/20\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9759 - loss: 0.0752 - val_accuracy: 0.9714 - val_loss: 0.1021\n",
      "Epoch 9/20\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9784 - loss: 0.0688 - val_accuracy: 0.9720 - val_loss: 0.0996\n",
      "Epoch 10/20\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.0648 - val_accuracy: 0.9719 - val_loss: 0.1022\n",
      "Epoch 11/20\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9800 - loss: 0.0609 - val_accuracy: 0.9723 - val_loss: 0.0978\n",
      "Epoch 12/20\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9835 - loss: 0.0521 - val_accuracy: 0.9735 - val_loss: 0.1001\n",
      "Epoch 13/20\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9817 - loss: 0.0560 - val_accuracy: 0.9737 - val_loss: 0.1010\n",
      "Epoch 14/20\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.0491 - val_accuracy: 0.9738 - val_loss: 0.0989\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "(      Metric     Value\n",
      "0   F1 Score  0.972242\n",
      "1  Precision  0.972277\n",
      "2     Recall  0.972262,      1    0    4    7    3    5    8    9    2    6\n",
      "1  812    0    2    2    1    1    6    0    2    1\n",
      "0    0  927    4    1    0    0    0    1    4    0\n",
      "4    4    0  813    4    4    0    1    4    4    1\n",
      "7    2    0   10  832    0   11    0    4    6    5\n",
      "3    0    1    0    0  799    0    3    0    0   11\n",
      "5    3    2    0    8    2  729    7    0    4    4\n",
      "8    2    0    0    0    0    5  818    0    2    0\n",
      "9    0    4    4    6    6    1    0  849    2    8\n",
      "2    4    6    2    0    0    5    4    1  786    5\n",
      "6    5    0    0    4   13    3    0    4    7  802)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "mlp_classifier = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_norm.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "mlp_classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "mlp_classifier.fit(\n",
    "    X_train_norm, \n",
    "    y_train, \n",
    "    epochs=20, \n",
    "    batch_size=64,\n",
    "    validation_data=(X_valid_norm, y_valid),\n",
    "    callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "y_pred_proba = mlp_classifier.predict(X_valid_norm)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "mlp_classifier_assessment = evaluate_classifier(y_valid, np.round(y_pred))\n",
    "print(mlp_classifier_assessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Collecting torch==2.5.1 (from torchvision)\n",
      "  Using cached torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: filelock in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/yanncauchepin/Git/.venv/lib/python3.12/site-packages (from jinja2->torch==2.5.1->torchvision) (2.1.5)\n",
      "Downloading torchvision-0.20.1-cp312-cp312-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m776.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m00:21\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.0\n",
      "    Uninstalling torch-2.5.0:\n",
      "      Successfully uninstalled torch-2.5.0\n",
      "Successfully installed torch-2.5.1 torchvision-0.20.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: torch.tensor(x.reshape(28, 28), dtype=torch.float32).unsqueeze(0)),  # Reshape and add channel\n",
    "    transforms.Resize((224, 224)),                                                                  # Resize to 224x224\n",
    "    transforms.Lambda(lambda x: x.expand(3, -1, -1)),                                               # Duplicate channels to create RGB\n",
    "    transforms.Normalize((0.5,), (0.5,))                                                            # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Apply transformations on training and validation sets\n",
    "X_train_transformed = torch.stack([transform(x) for x in X_train]) \n",
    "X_valid_transformed = torch.stack([transform(x) for x in X_valid])  # Transform each item in X_valid\n",
    "\n",
    "# Convert labels to tensors\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_valid_tensor = torch.tensor(y_valid, dtype=torch.long)\n",
    "\n",
    "# Create TensorDatasets and DataLoaders for batch processing\n",
    "train_dataset = TensorDataset(X_train_transformed, y_train_tensor)\n",
    "valid_dataset = TensorDataset(X_valid_transformed, y_valid_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "vit_classifier = ViTForImageClassification.from_pretrained(\n",
    "    'google/vit-base-patch16-224-in21k', \n",
    "    num_labels=10 \n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vit_classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "optimizer = AdamW(vit_classifier.parameters(), lr=1e-5)\n",
    "\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    vit_classifier.train()\n",
    "    train_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = vit_classifier(inputs)\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "vit_classifier.eval()\n",
    "all_vit_classifier_preds, all_vit_classifier_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in valid_loader:\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = vit_classifier(inputs)\n",
    "        preds = torch.argmax(outputs.logits, axis=1)\n",
    "        \n",
    "        all_vit_classifier_preds.extend(preds.cpu().numpy())\n",
    "        all_vit_classifier_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(all_vit_classifier_labels, all_vit_classifier_preds)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(all_vit_classifier_labels, all_vit_classifier_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_classifier_assessement = evaluate_classifier(all_vit_classifier_labels, all_vit_classifier_preds)\n",
    "print(vit_classifier_assessement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "class DigitCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DigitCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)  # Flatten for fully connected layer\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x.reshape(28, 28).astype(np.float32)),\n",
    "    transforms.ToTensor(), \n",
    "])\n",
    "\n",
    "X_train_transformed = torch.stack([transform(x) for x in X_train])\n",
    "X_valid_transformed = torch.stack([transform(x) for x in X_valid])\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "y_valid_tensor = torch.tensor(y_valid)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_transformed, y_train_tensor)\n",
    "valid_dataset = TensorDataset(X_valid_transformed, y_valid_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=8)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn_classifier = DigitCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_classifier.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    cnn_classifier.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn_classifier(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "cnn_classifier.eval()\n",
    "all_cnn_classifier_preds, all_cnn_classifier_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in valid_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = cnn_classifier(inputs)\n",
    "        preds = torch.argmax(outputs, axis=1)\n",
    "        \n",
    "        all_cnn_classifier_preds.extend(preds.cpu().numpy())\n",
    "        all_cnn_classifier_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy and classification report\n",
    "accuracy = accuracy_score(all_cnn_classifier_labels, all_cnn_classifier_preds)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(all_cnn_classifier_labels, all_cnn_classifier_preds))\n",
    "cnn_classifier_assessement = evaluate_classifier(all_cnn_classifier_labels, all_cnn_classifier_preds)\n",
    "print(cnn_classifier_assessement)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
