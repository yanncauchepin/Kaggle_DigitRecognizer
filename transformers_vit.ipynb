{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **HuggingFace Login**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd10bf6bb11c45b89eddba148f541dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Libairies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Read Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df_train = pd.read_csv('/media/yanncauchepin/ExternalDisk/Datasets/ComputerVisionImages/digit_recognizer/train.csv')\n",
    "df_test = pd.read_csv('/media/yanncauchepin/ExternalDisk/Datasets/ComputerVisionImages/digit_recognizer/test.csv')\n",
    "'''\n",
    "df_train = pd.read_csv('C:/Users/cauchepy/Datasets/ComputerVisionImages/kaggle_digitrecognizer/train.csv')\n",
    "df_test = pd.read_csv('C:/Users/cauchepy/Datasets/ComputerVisionImages/kaggle_digitrecognizer/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Short Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count\n",
       "label       \n",
       "1       4684\n",
       "7       4401\n",
       "3       4351\n",
       "9       4188\n",
       "2       4177\n",
       "6       4137\n",
       "0       4132\n",
       "4       4072\n",
       "8       4063\n",
       "5       3795"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distinct_labels = df_train['label'].value_counts()\n",
    "display(pd.DataFrame(distinct_labels))\n",
    "classes = len(df_train[\"label\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocess Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(df_train['label'])\n",
    "X_train = np.array(df_train.drop('label', axis=1))\n",
    "X_test = np.array(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Assessment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(y_true, y_pred):\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Metric': ['F1 Score', 'Precision', 'Recall'],\n",
    "        'Value': [f1, precision, recall]\n",
    "    })\n",
    "    \n",
    "    cm_df = pd.DataFrame(cm, columns=df_train[\"label\"].unique(), index=df_train[\"label\"].unique())\n",
    "    \n",
    "    return metrics_df, cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:100]\n",
    "y_train = y_train[:100]\n",
    "X_valid = X_valid[:100]\n",
    "y_valid = y_valid[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Transformers VIT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 290.70it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 294.21it/s]\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\cauchepy\\Code\\.venv\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "100%|██████████| 2/2 [00:19<00:00,  9.92s/it]\n",
      "  3%|▎         | 1/30 [00:19<09:35, 19.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Training Loss: 2.3238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:29<00:00, 14.99s/it]\n",
      "  7%|▋         | 2/30 [00:49<12:02, 25.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Training Loss: 2.2958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:37<00:00, 18.92s/it]\n",
      " 10%|█         | 3/30 [01:27<14:05, 31.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Training Loss: 2.2813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:38<00:00, 19.44s/it]\n",
      " 13%|█▎        | 4/30 [02:06<14:51, 34.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Training Loss: 2.2681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:39<00:00, 19.98s/it]\n",
      " 17%|█▋        | 5/30 [02:46<15:08, 36.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Training Loss: 2.2502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:41<00:00, 20.97s/it]\n",
      " 20%|██        | 6/30 [03:28<15:17, 38.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Training Loss: 2.2327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:46<00:00, 23.29s/it]\n",
      " 23%|██▎       | 7/30 [04:15<15:42, 40.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Training Loss: 2.2157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:43<00:00, 21.93s/it]\n",
      " 27%|██▋       | 8/30 [04:58<15:21, 41.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Training Loss: 2.1958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:42<00:00, 21.41s/it]\n",
      " 30%|███       | 9/30 [05:41<14:45, 42.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Training Loss: 2.1769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:41<00:00, 20.74s/it]\n",
      " 33%|███▎      | 10/30 [06:23<13:59, 41.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Training Loss: 2.1508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:45<00:00, 22.63s/it]\n",
      " 37%|███▋      | 11/30 [07:08<13:36, 42.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Training Loss: 2.1414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:45<00:00, 22.90s/it]\n",
      " 40%|████      | 12/30 [07:54<13:08, 43.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Training Loss: 2.1192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:42<00:00, 21.34s/it]\n",
      " 43%|████▎     | 13/30 [08:36<12:19, 43.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Training Loss: 2.0977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:46<00:00, 23.13s/it]\n",
      " 47%|████▋     | 14/30 [09:23<11:49, 44.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Training Loss: 2.0695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from transformers import ViTForImageClassification, ViTImageProcessor, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from PIL import Image\n",
    "\n",
    "processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "def preprocess_images(images):\n",
    "    # Convert to PIL Images\n",
    "    pil_images = [Image.fromarray((img * 255).astype(np.uint8)).convert(\"RGB\") if isinstance(img, np.ndarray) else img.convert(\"RGB\") for img in images]\n",
    "    processed_inputs = processor(images=pil_images, return_tensors=\"pt\")['pixel_values']\n",
    "    return processed_inputs\n",
    "\n",
    "X_train_tensor = preprocess_images(X_train)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_valid_tensor = preprocess_images(X_valid)\n",
    "y_valid_tensor = torch.tensor(y_valid, dtype=torch.long)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "valid_dataset = TensorDataset(X_valid_tensor, y_valid_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "# Initialize ViT model\n",
    "vit_classifier = ViTForImageClassification.from_pretrained(\n",
    "    'google/vit-base-patch16-224-in21k', \n",
    "    num_labels=10\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vit_classifier.to(device)\n",
    "\n",
    "# Training setup\n",
    "optimizer = AdamW(vit_classifier.parameters(), lr=1e-5)\n",
    "epochs = 3\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    vit_classifier.train()\n",
    "    train_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = vit_classifier(inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "# Evaluation on validation set\n",
    "vit_classifier.eval()\n",
    "all_vit_classifier_preds, all_vit_classifier_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in valid_loader:\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = vit_classifier(inputs)\n",
    "        preds = torch.argmax(outputs.logits, axis=1)\n",
    "        \n",
    "        all_vit_classifier_preds.extend(preds.cpu().numpy())\n",
    "        all_vit_classifier_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy and classification report\n",
    "accuracy = accuracy_score(all_vit_classifier_labels, all_vit_classifier_preds)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(all_vit_classifier_labels, all_vit_classifier_preds))\n",
    "\n",
    "# Additional assessment (if function `evaluate_classifier` is defined)\n",
    "vit_classifier_assessment = evaluate_classifier(all_vit_classifier_labels, all_vit_classifier_preds)\n",
    "print(vit_classifier_assessment)\n",
    "\n",
    "vit_classifier.push_to_hub(\"yanncauchepin/kaggle_digitrecognizer_vit_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9334 [00:00<?, ?it/s]/tmp/ipykernel_25585/3633612418.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.files[idx])\n",
      "100%|██████████| 9334/9334 [34:53<00:00,  4.46it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'Dataset' has no attribute 'from_pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 50\u001b[0m\n\u001b[1;32m     44\u001b[0m         test_preds\u001b[38;5;241m.\u001b[39mextend(preds\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     46\u001b[0m vit_classifier_submission_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageId\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(test_preds) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_preds\n\u001b[1;32m     49\u001b[0m })\n\u001b[0;32m---> 50\u001b[0m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m(vit_classifier_submission_df)\u001b[38;5;241m.\u001b[39mpush_to_hub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myanncauchepin/kaggle_digitrecognizer_vit_submission_df.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'Dataset' has no attribute 'from_pandas'"
     ]
    }
   ],
   "source": [
    "X_test_tensor = preprocess_images(X_test)\n",
    "test_dataset = TensorDataset(X_test_tensor)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=3)\n",
    "\n",
    "vit_classifier.eval()\n",
    "test_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        inputs = batch.to(device)  \n",
    "        outputs = vit_classifier(inputs)\n",
    "        preds = torch.argmax(outputs.logits, axis=1)\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "vit_classifier_submission_df = pd.DataFrame({\n",
    "    \"ImageId\": range(1, len(test_preds) + 1),\n",
    "    \"Label\": test_preds\n",
    "})\n",
    "from datasets import Dataset\n",
    "Dataset.from_pandas(vit_classifier_submission_df).push_to_hub(\"yanncauchepin/kaggle_digitrecognizer_vit_submission_df\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
